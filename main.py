# ConstruÃ§Ã£o de Compiladores
# Compilador, arquivo principal
# Enthony e Samantha

import csv
import time

from termcolor import colored

from tokens import Token
from lexico import Lexer
from sintatico import Sintatico

def main():
  # Defina o nome do arquivo de entrada (cÃ³digo fonte)
  source_code = "test/syntax_tests/Test3.pas"  # Ex.: 'test/syntax_tests/Test1.pas'
  print(f"ðŸ“ƒ Analisando o arquivo: {colored(source_code, 'cyan', 'on_cyan')}\n")
  with open(source_code, 'r') as f: 
    source_code = f.read()
  # print(source_code)

  # Defina o nome do arquivo de saÃ­da para o analisador lÃ©xico e sintÃ¡tico
  lexer_file = "lex_output.csv"        # Ex.: 'outputs/lexer_o/result1.csv'
  syntax_file = "sint_output.csv"      # Ex.: 'outputs/syntax_o/result1.csv'

  # Limpa o conteÃºdo dos arquivos, se existirem
  open(lexer_file, 'w').close()
  open(syntax_file, 'w').close()

  # Realiza a anÃ¡lise lÃ©xica a partir de um cÃ³digo fonte
  print("âŒ› Inicializando anÃ¡lise lÃ©xica...")
  lexer = Lexer()
  lexer.set_source_code(source_code=source_code)
  lexer.set_output_lexer(output_lexer=lexer_file)
  lexer.tokenize()

  with open(lexer.output_lexer, 'a', newline='') as csvfile:
    fieldnames = ['Token', 'ClassificaÃ§Ã£o', 'Linha']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    writer.writeheader()  # Escreva o cabeÃ§alho do CSV
    for token in lexer.tokens:
      writer.writerow({'Token': token.value, 'ClassificaÃ§Ã£o': token.type, 'Linha': token.line})

  if lexer.lexer_errors != 0:
    print(colored(f"AnÃ¡lise lÃ©xica finalizada com {lexer.lexer_errors} erros.","red"))
  else:
    print(colored("âœ… AnÃ¡lise lÃ©xica concluÃ­da com sucesso.","green"))

  # Realiza a anÃ¡lise sintÃ¡tica a partir da saÃ­da do analisador lÃ©xico
  print("\nâŒ› Inicializando anÃ¡lise sintÃ¡tica e semÃ¢ntica...")
  if (lexer.lexer_errors == 0):
    lista_tokens = []
    with open(lexer_file, 'r') as csvfile:
      leitor = csv.DictReader(csvfile)
      for linha in leitor:
        # criando uma tupla com o prÃ³prio token, o seu tipo e a linha que se encontra
        lista_tokens.append(Token(linha['ClassificaÃ§Ã£o'], linha['Token'], int(linha['Linha'])))

    sintatico = Sintatico(lista_tokens)
    sintatico.analisar()

  else:
    print(f"\nNÃ£o foi possÃ­vel realizar a anÃ¡lise sintÃ¡tica e semÃ¢ntica, pois erros foram encontrados durante a anÃ¡lise lÃ©xica.")
    print("Encerrando.")

  # Em breve: realizaÃ§Ã£o da anÃ¡lise semÃ¢ntica -> projeto final

if __name__ == "__main__":
  print(colored("* * * Projeto de Compiladores\n", "cyan"))
  main()